"""
çˆ¬è™«åŸºç±»å’Œ Job æ•°æ®æ¨¡å‹
"""
from abc import ABC, abstractmethod
from dataclasses import dataclass, field, asdict
from datetime import datetime
from typing import Optional
import hashlib
import logging

logger = logging.getLogger(__name__)


@dataclass
class Job:
    """èŒä½æ•°æ®æ¨¡å‹"""
    
    # å¿…å¡«å­—æ®µ
    title: str
    company: str
    url: str
    source: str  # æ•°æ®æ¥æºï¼ˆå¦‚ "Paradigm Portfolio"ï¼‰
    
    # å¯é€‰å­—æ®µ
    location: str = ""
    salary: str = ""
    job_type: str = ""  # Full-time, Part-time, Contract ç­‰
    remote: bool = False
    description: str = ""
    posted_date: str = ""
    
    # å…ƒæ•°æ®
    scraped_at: str = field(default_factory=lambda: datetime.utcnow().isoformat())
    
    @property
    def unique_id(self) -> str:
        """ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºå»é‡"""
        # ä½¿ç”¨ title + company + url ç”Ÿæˆå”¯ä¸€ID
        key = f"{self.title.lower()}|{self.company.lower()}|{self.url}"
        return hashlib.md5(key.encode()).hexdigest()
    
    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        data = asdict(self)
        data["unique_id"] = self.unique_id
        return data
    
    @classmethod
    def from_dict(cls, data: dict) -> "Job":
        """ä»å­—å…¸åˆ›å»º Job å¯¹è±¡"""
        # ç§»é™¤ unique_idï¼Œå› ä¸ºå®ƒæ˜¯è®¡ç®—å±æ€§
        data = {k: v for k, v in data.items() if k != "unique_id"}
        return cls(**data)
    
    def format_telegram_message(self) -> str:
        """æ ¼å¼åŒ–ä¸º Telegram æ¶ˆæ¯"""
        lines = [
            f"ğŸ“Œ <b>{self._escape_html(self.title)}</b>",
            f"ğŸ¢ {self._escape_html(self.company)}",
            f"ğŸ“‚ <i>via {self._escape_html(self.source)}</i>",
        ]
        
        if self.location:
            location_text = self.location
            if self.remote:
                location_text += " (Remote OK)"
            lines.append(f"ğŸ“ {self._escape_html(location_text)}")
        elif self.remote:
            lines.append("ğŸ“ Remote")
        
        if self.salary:
            lines.append(f"ğŸ’° {self._escape_html(self.salary)}")
        
        if self.job_type:
            lines.append(f"â° {self._escape_html(self.job_type)}")
        
        lines.extend([
            "",
            f"ğŸ”— <a href=\"{self.url}\">Apply Now</a>",
        ])
        
        # æ·»åŠ æ ‡ç­¾
        tags = self._generate_tags()
        if tags:
            lines.extend(["", tags])
        
        return "\n".join(lines)
    
    def _escape_html(self, text: str) -> str:
        """è½¬ä¹‰ HTML ç‰¹æ®Šå­—ç¬¦"""
        return (
            text.replace("&", "&amp;")
            .replace("<", "&lt;")
            .replace(">", "&gt;")
        )
    
    def _generate_tags(self) -> str:
        """ç”Ÿæˆæ ‡ç­¾"""
        tags = ["#crypto", "#web3"]
        
        title_lower = self.title.lower()
        
        if any(kw in title_lower for kw in ["research", "analyst"]):
            tags.append("#research")
        if any(kw in title_lower for kw in ["invest", "vc", "venture", "principal"]):
            tags.append("#investment")
        if any(kw in title_lower for kw in ["strateg"]):
            tags.append("#strategy")
        if any(kw in title_lower for kw in ["operation", "ops"]):
            tags.append("#operations")
        if any(kw in title_lower for kw in ["business development", " bd ", "partner"]):
            tags.append("#bizdev")
        if any(kw in title_lower for kw in ["growth", "marketing"]):
            tags.append("#growth")
        if any(kw in title_lower for kw in ["product"]):
            tags.append("#product")
        if any(kw in title_lower for kw in ["community"]):
            tags.append("#community")
        
        return " ".join(tags[:5])  # æœ€å¤š5ä¸ªæ ‡ç­¾


class BaseScraper(ABC):
    """çˆ¬è™«åŸºç±»"""
    
    def __init__(self, name: str, source_name: str):
        """
        åˆå§‹åŒ–çˆ¬è™«
        
        Args:
            name: çˆ¬è™«åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            source_name: æ•°æ®æºåç§°ï¼ˆæ˜¾ç¤ºåœ¨æ¶ˆæ¯ä¸­ï¼‰
        """
        self.name = name
        self.source_name = source_name
        self.logger = logging.getLogger(f"scraper.{name}")
    
    @abstractmethod
    def fetch_jobs(self) -> list[Job]:
        """
        è·å–èŒä½åˆ—è¡¨
        
        Returns:
            Job å¯¹è±¡åˆ—è¡¨
        """
        pass
    
    def scrape(self) -> list[Job]:
        """
        æ‰§è¡Œçˆ¬å–ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
        
        Returns:
            Job å¯¹è±¡åˆ—è¡¨
        """
        try:
            self.logger.info(f"Starting scrape: {self.name}")
            jobs = self.fetch_jobs()
            self.logger.info(f"Scraped {len(jobs)} jobs from {self.name}")
            return jobs
        except Exception as e:
            self.logger.error(f"Error scraping {self.name}: {e}")
            return []
